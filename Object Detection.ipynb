{"cells":[{"metadata":{},"cell_type":"markdown","source":"beaver,\ndolphin, \notter, \nseal,\nwhale, \naquarium fish,\nflatfish, \nray,\nshark,\ntrout, \norchids,\npoppies,\nroses,\nsunflowers,\ntulips, \nbottles,\nbowls, \ncans,\ncups,\nplates, \napples,\nmushrooms,\noranges,\npears,\nsweet peppers, \nclock, \ncomputer keyboard,\nlamp,\ntelephone,\ntelevision, \nbed,\nchair, \ncouch,\ntable,\nwardrobe, \nbee,\nbeetle,\nbutterfly,\ncaterpillar,\ncockroach, \nbear,\nleopard,\nlion,\ntiger, \nwolf, \nbridge, \ncastle, \nhouse,\nroad, \nskyscraper, \ncloud,\nforest,\nmountain,\nplain,\nsea, \ncamel,\ncattle,\nchimpanzee, \nelephant,\nkangaroo, \nfox,\nporcupine,\npossum, \nraccoon, \nskunk, \ncrab,\nlobster, \nsnail,\nspider,\nworm, \nbaby,\nboy,\ngirl,\nman,\nwoman, \ncrocodile,\ndinosaur, \nlizard, \nsnake,\nturtle, \nhamster,\nmouse,\nrabbit,\nshrew,\nsquirrel, \nmaple,\noak,\npalm,\npine,\nwillow, \nbicycle,\nbus,\nmotorcycle,\npickup truck,\ntrain, \nlawn-mower,\nrocket,\nstreetcar,\ntank, \ntractor,\nT-shirt/top,\nTrouser,\nPullover,\nDress,\nCoat,\nSandal,\nShirt,\nSneaker,\nBag,\nAnkle boot,"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from tensorflow.keras.datasets import cifar100\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.datasets import mnist\nimport numpy as np\nimport cv2\nfrom tensorflow import keras\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","execution_count":26,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Getting data using built-in tensorflow.keras.datasets API\n(input_train_cifar10, target_train_cifar10), (input_test_cifar10, target_test_cifar10) = cifar10.load_data()\n(input_train_cifar100, target_train_cifar100), (input_test_cifar100, target_test_cifar100) = cifar100.load_data()\n(input_train_mnist, target_train_mnist), (input_test_mnist, target_test_mnist) = mnist.load_data()","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#To detect many of the daily life objects, combination of all datasets is required.\n\ntrain_features_set_1 = [] #Storing images combined from all datasets\ntrain_labels_set_1 = []   #Storing labels combined from all datasets\nresult = []        \nstart = 100               #Index for data added from other datasets\n\n#Add CIFAR-100 data to train_features_set_1 after converting to grayscale and removing RGB layer\nfor i in range(len(input_train_cifar100)):\n    train_features_set_1.append(np.mean(input_train_cifar100[i],axis=2).reshape((32,32,1)))\n    train_labels_set_1.append(target_train_cifar100[i])\n    \n#Add CIFAR-10 data to train_features_set_1 after converting to grayscale and removing RGB layer\nfor i in range(10):\n    if i == 1: continue\n    result = np.where(target_train_cifar10 == i)\n    result = result[0][:500]\n    for j in result:\n        train_features_set_1.append(np.mean(input_train_cifar10[j],axis=2).reshape((32,32,1)))\n        train_labels_set_1.append([start])\n    start = start + 1\n\n#Add MNIST-Fashion after resizing to 32 x 32 and converting to (32,32,1) format\nfor i in range(10):\n    result = np.where(target_train_mnist == i)\n    result = result[0][:500]\n    for j in result:\n        train_features_set_1.append(cv2.resize(input_train_mnist[j],dsize=(32,32),interpolation=cv2.INTER_AREA).reshape((32,32,1)))\n        train_labels_set_1.append([start])\n    start = start + 1\n\n#Convert both arrays to numpy\ntrain_features_set_1 = np.array(train_features_set_1)\ntrain_labels_set_1 = np.array(train_labels_set_1)\n\n#Perform shuffling on arrays. Neural Network gives better accuracy when arrays are shuffled rather than when in order\nstate = np.random.get_state()\nnp.random.shuffle(train_features_set_1)\nnp.random.set_state(state)\nnp.random.shuffle(train_labels_set_1)\n\n#Observe the classes and samples per class to make sure of the count\nprint(train_features_set_1.shape)\nun,count = np.unique(train_labels_set_1,return_counts=True)\nprint(un,count)","execution_count":31,"outputs":[{"output_type":"stream","text":"(59500, 32, 32, 1)\n[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118] [500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500 500\n 500 500 500 500 500 500 500 500 500 500 500]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = keras.models.Sequential()\nmodel.add(keras.layers.Conv2D(32,(3,3),activation='relu',input_shape=(32,32,1)))\nmodel.add(keras.layers.MaxPooling2D((2,2)))\nmodel.add(keras.layers.Conv2D(64,(3,3),activation='relu'))\nmodel.add(keras.layers.MaxPooling2D((3,3)))\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(4*4*64, activation='relu'))\nmodel.add(keras.layers.Dense(119, activation='softmax'))\nmodel.summary()\n\noptimizer = keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer,\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\nep = 10\nmodel.fit(train_features_set_1, train_labels_set_1, epochs=ep)","execution_count":null,"outputs":[{"output_type":"stream","text":"Model: \"sequential_27\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_54 (Conv2D)           (None, 30, 30, 32)        320       \n_________________________________________________________________\nmax_pooling2d_54 (MaxPooling (None, 15, 15, 32)        0         \n_________________________________________________________________\nconv2d_55 (Conv2D)           (None, 13, 13, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_55 (MaxPooling (None, 4, 4, 64)          0         \n_________________________________________________________________\nflatten_27 (Flatten)         (None, 1024)              0         \n_________________________________________________________________\ndense_66 (Dense)             (None, 1024)              1049600   \n_________________________________________________________________\ndense_67 (Dense)             (None, 119)               121975    \n=================================================================\nTotal params: 1,190,391\nTrainable params: 1,190,391\nNon-trainable params: 0\n_________________________________________________________________\nTrain on 59500 samples\nEpoch 1/10\n30688/59500 [==============>...............] - ETA: 26s - loss: 5.4952 - accuracy: 0.0996","name":"stdout"}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}